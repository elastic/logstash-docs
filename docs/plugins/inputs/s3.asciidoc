[[plugins-inputs-s3]]
=== s3

* Version: 3.1.2
* Released on: January 24, 2017
* https://github.com/logstash-plugins/logstash-input-s3/blob/master/CHANGELOG.md#312[Changelog]



==== Getting Help

For questions about the plugin, open a topic in the http://discuss.elastic.co[Discuss] forums. For bugs or feature requests, open an issue in https://github.com/elastic/logstash[Github].
For the list of Elastic supported plugins, please consult the https://www.elastic.co/support/matrix#show_logstash_plugins[Elastic Support Matrix].

==== Description

Stream events from files from a S3 bucket.

Each line from each file generates an event.
Files ending in `.gz` are handled as gzip'ed files.

&nbsp;

==== Synopsis

This plugin supports the following configuration options:

Required configuration options:

[source,json]
--------------------------
s3 {
    bucket => ...
}
--------------------------



Available configuration options:

[cols="<,<,<",options="header",]
|=======================================================================
|Setting |Input type|Required
| <<plugins-inputs-s3-access_key_id>> |<<string,string>>|No
| <<plugins-inputs-s3-add_field>> |<<hash,hash>>|No
| <<plugins-inputs-s3-aws_credentials_file>> |<<string,string>>|No
| <<plugins-inputs-s3-backup_add_prefix>> |<<string,string>>|No
| <<plugins-inputs-s3-backup_to_bucket>> |<<string,string>>|No
| <<plugins-inputs-s3-backup_to_dir>> |<<string,string>>|No
| <<plugins-inputs-s3-bucket>> |<<string,string>>|Yes
| <<plugins-inputs-s3-codec>> |<<codec,codec>>|No
| <<plugins-inputs-s3-delete>> |<<boolean,boolean>>|No
| <<plugins-inputs-s3-enable_metric>> |<<boolean,boolean>>|No
| <<plugins-inputs-s3-exclude_pattern>> |<<string,string>>|No
| <<plugins-inputs-s3-id>> |<<string,string>>|No
| <<plugins-inputs-s3-interval>> |<<number,number>>|No
| <<plugins-inputs-s3-prefix>> |<<string,string>>|No
| <<plugins-inputs-s3-proxy_uri>> |<<string,string>>|No
| <<plugins-inputs-s3-region>> |<<string,string>>, one of `["us-east-1", "us-west-1", "us-west-2", "eu-central-1", "eu-west-1", "ap-southeast-1", "ap-southeast-2", "ap-northeast-1", "ap-northeast-2", "sa-east-1", "us-gov-west-1", "cn-north-1", "ap-south-1"]`|No
| <<plugins-inputs-s3-secret_access_key>> |<<string,string>>|No
| <<plugins-inputs-s3-session_token>> |<<string,string>>|No
| <<plugins-inputs-s3-sincedb_path>> |<<string,string>>|No
| <<plugins-inputs-s3-tags>> |<<array,array>>|No
| <<plugins-inputs-s3-temporary_directory>> |<<string,string>>|No
| <<plugins-inputs-s3-type>> |<<string,string>>|No
|=======================================================================


==== Details

&nbsp;

[[plugins-inputs-s3-access_key_id]]
===== `access_key_id` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

This plugin uses the AWS SDK and supports several ways to get credentials, which will be tried in this order:

1. Static configuration, using `access_key_id` and `secret_access_key` params in logstash plugin config
2. External credentials file specified by `aws_credentials_file`
3. Environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`
4. Environment variables `AMAZON_ACCESS_KEY_ID` and `AMAZON_SECRET_ACCESS_KEY`
5. IAM Instance Profile (available when running inside EC2)

[[plugins-inputs-s3-add_field]]
===== `add_field` 

  * Value type is <<hash,hash>>
  * Default value is `{}`

Add a field to an event

[[plugins-inputs-s3-aws_credentials_file]]
===== `aws_credentials_file` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Path to YAML file containing a hash of AWS credentials.
This file will only be loaded if `access_key_id` and
`secret_access_key` aren't set. The contents of the
file should look like this:

[source,ruby]
----------------------------------
    :access_key_id: "12345"
    :secret_access_key: "54321"
----------------------------------


[[plugins-inputs-s3-backup_add_prefix]]
===== `backup_add_prefix` 

  * Value type is <<string,string>>
  * Default value is `nil`

Append a prefix to the key (full path including file name in s3) after processing.
If backing up to another (or the same) bucket, this effectively lets you
choose a new 'folder' to place the files in

[[plugins-inputs-s3-backup_to_bucket]]
===== `backup_to_bucket` 

  * Value type is <<string,string>>
  * Default value is `nil`

Name of a S3 bucket to backup processed files to.

[[plugins-inputs-s3-backup_to_dir]]
===== `backup_to_dir` 

  * Value type is <<string,string>>
  * Default value is `nil`

Path of a local directory to backup processed files to.

[[plugins-inputs-s3-bucket]]
===== `bucket` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.

The name of the S3 bucket.

[[plugins-inputs-s3-codec]]
===== `codec` 

  * Value type is <<codec,codec>>
  * Default value is `"plain"`

The codec used for input data. Input codecs are a convenient method for decoding your data before it enters the input, without needing a separate filter in your Logstash pipeline.

[[plugins-inputs-s3-delete]]
===== `delete` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Whether to delete processed files from the original bucket.

[[plugins-inputs-s3-enable_metric]]
===== `enable_metric` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Disable or enable metric logging for this specific plugin instance
by default we record all the metrics we can, but you can disable metrics collection
for a specific plugin.

[[plugins-inputs-s3-exclude_pattern]]
===== `exclude_pattern` 

  * Value type is <<string,string>>
  * Default value is `nil`

Ruby style regexp of keys to exclude from the bucket

[[plugins-inputs-s3-id]]
===== `id` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Add a unique `ID` to the plugin configuration. If no ID is specified, Logstash will generate one. 
It is strongly recommended to set this ID in your configuration. This is particularly useful 
when you have two or more plugins of the same type, for example, if you have 2 grok filters. 
Adding a named ID in this case will help in monitoring Logstash when using the monitoring APIs.

[source,ruby]
---------------------------------------------------------------------------------------------------
output {
 stdout {
   id => "my_plugin_id"
 }
}
---------------------------------------------------------------------------------------------------


[[plugins-inputs-s3-interval]]
===== `interval` 

  * Value type is <<number,number>>
  * Default value is `60`

Interval to wait between to check the file list again after a run is finished.
Value is in seconds.

[[plugins-inputs-s3-prefix]]
===== `prefix` 

  * Value type is <<string,string>>
  * Default value is `nil`

If specified, the prefix of filenames in the bucket must match (not a regexp)

[[plugins-inputs-s3-proxy_uri]]
===== `proxy_uri` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

URI to proxy server if required

[[plugins-inputs-s3-region]]
===== `region` 

  * Value can be any of: `us-east-1`, `us-west-1`, `us-west-2`, `eu-central-1`, `eu-west-1`, `ap-southeast-1`, `ap-southeast-2`, `ap-northeast-1`, `ap-northeast-2`, `sa-east-1`, `us-gov-west-1`, `cn-north-1`, `ap-south-1`
  * Default value is `"us-east-1"`

The AWS Region

[[plugins-inputs-s3-secret_access_key]]
===== `secret_access_key` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The AWS Secret Access Key

[[plugins-inputs-s3-session_token]]
===== `session_token` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The AWS Session token for temporary credential

[[plugins-inputs-s3-sincedb_path]]
===== `sincedb_path` 

  * Value type is <<string,string>>
  * Default value is `nil`

Where to write the since database (keeps track of the date
the last handled file was added to S3). The default will write
sincedb files to some path matching "$HOME/.sincedb*"
Should be a path with filename not just a directory.

[[plugins-inputs-s3-tags]]
===== `tags` 

  * Value type is <<array,array>>
  * There is no default value for this setting.

Add any number of arbitrary tags to your event.

This can help with processing later.

[[plugins-inputs-s3-temporary_directory]]
===== `temporary_directory` 

  * Value type is <<string,string>>
  * Default value is `"/var/folders/_9/x4bq65rs6vd0rrjthct3zxjw0000gn/T/logstash"`

Set the directory where logstash will store the tmp files before processing them.
default to the current OS temporary directory in linux /tmp/logstash

[[plugins-inputs-s3-type]]
===== `type` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

This is the base class for Logstash inputs.
Add a `type` field to all events handled by this input.

Types are used mainly for filter activation.

The type is stored as part of the event itself, so you can
also use the type to search for it in Kibana.

If you try to set a type on an event that already has one (for
example when you send an event from a shipper to an indexer) then
a new input will not override the existing type. A type set at
the shipper stays with that event for its life even
when sent to another Logstash server.


