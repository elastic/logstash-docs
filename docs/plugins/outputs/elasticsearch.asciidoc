[[plugins-outputs-elasticsearch]]
=== elasticsearch

This output lets you store logs in Elasticsearch and is the most recommended
output for Logstash. If you plan on using the Kibana web interface, you'll
need to use this output.

  *VERSION NOTE*: Your Elasticsearch cluster must be running Elasticsearch 1.0.0 or later.

If you want to set other Elasticsearch options that are not exposed directly
as configuration options, there are two methods:

* Create an `elasticsearch.yml` file in the $PWD of the Logstash process
* Pass in es.* java properties (`java -Des.node.foo=` or `ruby -J-Des.node.foo=`)

With the default `protocol` setting ("node"), this plugin will join your
Elasticsearch cluster as a client node, so it will show up in Elasticsearch's
cluster status.

You can learn more about Elasticsearch at <http://www.elasticsearch.org>

## Operational Notes

If using the default `protocol` setting ("node"), your firewalls might need
to permit port 9300 in *both* directions (from Logstash to Elasticsearch, and
Elasticsearch to Logstash)

&nbsp;

==== Synopsis

This plugin supports the following configuration options:


Required configuration options:

[source,json]
--------------------------
elasticsearch {
    aws_access_key => ... 
    aws_region => ... 
    aws_secret_key => ... 
}
--------------------------



Available configuration options:

[cols="<,<,<,<m",options="header",]
|=======================================================================
|Setting |Input type|Required|Default value
| <<plugins-outputs-elasticsearch-action>> |<<string,string>>|No|`"index"`
| <<plugins-outputs-elasticsearch-aws_access_key>> |<<string,string>>|Yes|
| <<plugins-outputs-elasticsearch-aws_protocol>> |<<string,string>>, one of `["http", "https"]`|No|`"https"`
| <<plugins-outputs-elasticsearch-aws_proxy_host>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-aws_proxy_port>> |<<number,number>>|No|
| <<plugins-outputs-elasticsearch-aws_region>> |<<string,string>>, one of `["us-east-1", "us-west-1", "us-west-2", "ap-southeast-1", "ap-southeast-2", "ap-northeast-1", "eu-west-1", "sa-east-1"]`|Yes|
| <<plugins-outputs-elasticsearch-aws_secret_key>> |<<string,string>>|Yes|
| <<plugins-outputs-elasticsearch-bind_host>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-bind_port>> |<<number,number>>|No|
| <<plugins-outputs-elasticsearch-cacert>> |a valid filesystem path|No|
| <<plugins-outputs-elasticsearch-cluster>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-codec>> |<<codec,codec>>|No|`"plain"`
| <<plugins-outputs-elasticsearch-document_id>> |<<string,string>>|No|`nil`
| <<plugins-outputs-elasticsearch-ec2_protocol>> |<<string,string>>, one of `["http", "https"]`|No|
| <<plugins-outputs-elasticsearch-embedded>> |<<boolean,boolean>>|No|`false`
| <<plugins-outputs-elasticsearch-embedded_http_port>> |<<string,string>>|No|`"9200-9300"`
| <<plugins-outputs-elasticsearch-flush_size>> |<<number,number>>|No|`5000`
| <<plugins-outputs-elasticsearch-host>> |<<array,array>>|No|
| <<plugins-outputs-elasticsearch-idle_flush_time>> |<<number,number>>|No|`1`
| <<plugins-outputs-elasticsearch-index>> |<<string,string>>|No|`"logstash-%{+YYYY.MM.dd}"`
| <<plugins-outputs-elasticsearch-index_type>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-manage_template>> |<<boolean,boolean>>|No|`true`
| <<plugins-outputs-elasticsearch-node_name>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-password>> |<<password,password>>|No|
| <<plugins-outputs-elasticsearch-port>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-protocol>> |<<string,string>>, one of `["node", "transport", "http"]`|No|
| <<plugins-outputs-elasticsearch-s3_protocol>> |<<string,string>>, one of `["http", "https"]`|No|
| <<plugins-outputs-elasticsearch-ssl>> |<<boolean,boolean>>|No|`false`
| <<plugins-outputs-elasticsearch-template>> |a valid filesystem path|No|
| <<plugins-outputs-elasticsearch-template_name>> |<<string,string>>|No|`"logstash"`
| <<plugins-outputs-elasticsearch-template_overwrite>> |<<boolean,boolean>>|No|`false`
| <<plugins-outputs-elasticsearch-truststore>> |a valid filesystem path|No|
| <<plugins-outputs-elasticsearch-truststore_password>> |<<password,password>>|No|
| <<plugins-outputs-elasticsearch-user>> |<<string,string>>|No|
| <<plugins-outputs-elasticsearch-workers>> |<<number,number>>|No|`1`
|=======================================================================


==== Details

&nbsp;

[[plugins-outputs-elasticsearch-action]]
===== `action` 

  * Value type is <<string,string>>
  * Default value is `"index"`

The Elasticsearch action to perform. Valid actions are: `index`, `delete`.

Use of this setting *REQUIRES* you also configure the `document_id` setting
because `delete` actions all require a document id.

What does each action do?

- index: indexes a document (an event from Logstash).
- delete: deletes a document by id

For more details on actions, check out the http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-bulk.html[Elasticsearch bulk API documentation]

[[plugins-outputs-elasticsearch-aws_access_key]]
===== `aws_access_key` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-aws_protocol]]
===== `aws_protocol` 

  * Value can be any of: `http`, `https`
  * Default value is `"https"`



[[plugins-outputs-elasticsearch-aws_proxy_host]]
===== `aws_proxy_host` 

  * Value type is <<string,string>>
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-aws_proxy_port]]
===== `aws_proxy_port` 

  * Value type is <<number,number>>
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-aws_region]]
===== `aws_region` 

  * This is a required setting.
  * Value can be any of: `us-east-1`, `us-west-1`, `us-west-2`, `ap-southeast-1`, `ap-southeast-2`, `ap-northeast-1`, `eu-west-1`, `sa-east-1`
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-aws_secret_key]]
===== `aws_secret_key` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-bind_host]]
===== `bind_host` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The name/address of the host to bind to for Elasticsearch clustering

[[plugins-outputs-elasticsearch-bind_port]]
===== `bind_port` 

  * Value type is <<number,number>>
  * There is no default value for this setting.

This is only valid for the 'node' protocol.

The port for the node to listen on.

[[plugins-outputs-elasticsearch-cacert]]
===== `cacert` 

  * Value type is <<path,path>>
  * There is no default value for this setting.

The .cer or .pem file to validate the server's certificate

[[plugins-outputs-elasticsearch-cluster]]
===== `cluster` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The name of your cluster if you set it on the Elasticsearch side. Useful
for discovery.

[[plugins-outputs-elasticsearch-codec]]
===== `codec` 

  * Value type is <<codec,codec>>
  * Default value is `"plain"`

The codec used for output data. Output codecs are a convenient method for encoding your data before it leaves the output, without needing a separate filter in your Logstash pipeline.

[[plugins-outputs-elasticsearch-document_id]]
===== `document_id` 

  * Value type is <<string,string>>
  * Default value is `nil`

The document ID for the index. Useful for overwriting existing entries in
Elasticsearch with the same ID.

[[plugins-outputs-elasticsearch-ec2_protocol]]
===== `ec2_protocol` 

  * Value can be any of: `http`, `https`
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-embedded]]
===== `embedded` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Run the Elasticsearch server embedded in this process.
This option is useful if you want to run a single Logstash process that
handles log processing and indexing; it saves you from needing to run
a separate Elasticsearch process.

[[plugins-outputs-elasticsearch-embedded_http_port]]
===== `embedded_http_port` 

  * Value type is <<string,string>>
  * Default value is `"9200-9300"`

If you are running the embedded Elasticsearch server, you can set the http
port it listens on here; it is not common to need this setting changed from
default.

[[plugins-outputs-elasticsearch-exclude_tags]]
===== `exclude_tags`  (DEPRECATED)

  * DEPRECATED WARNING: This configuration item is deprecated and may not be available in future versions.
  * Value type is <<array,array>>
  * Default value is `[]`

Only handle events without any of these tags. Note this check is additional to type and tags.

[[plugins-outputs-elasticsearch-flush_size]]
===== `flush_size` 

  * Value type is <<number,number>>
  * Default value is `5000`

This plugin uses the bulk index api for improved indexing performance.
To make efficient bulk api calls, we will buffer a certain number of
events before flushing that out to Elasticsearch. This setting
controls how many events will be buffered before sending a batch
of events.

[[plugins-outputs-elasticsearch-host]]
===== `host` 

  * Value type is <<array,array>>
  * There is no default value for this setting.

The hostname or IP address of the host to use for Elasticsearch unicast discovery
This is only required if the normal multicast/cluster discovery stuff won't
work in your environment.

    `"127.0.0.1"`
    `["127.0.0.1:9300","127.0.0.2:9300"]`

[[plugins-outputs-elasticsearch-idle_flush_time]]
===== `idle_flush_time` 

  * Value type is <<number,number>>
  * Default value is `1`

The amount of time since last flush before a flush is forced.

This setting helps ensure slow event rates don't get stuck in Logstash.
For example, if your `flush_size` is 100, and you have received 10 events,
and it has been more than `idle_flush_time` seconds since the last flush,
Logstash will flush those 10 events automatically.

This helps keep both fast and slow log streams moving along in
near-real-time.

[[plugins-outputs-elasticsearch-index]]
===== `index` 

  * Value type is <<string,string>>
  * Default value is `"logstash-%{+YYYY.MM.dd}"`

The index to write events to. This can be dynamic using the `%{foo}` syntax.
The default value will partition your indices by day so you can more easily
delete old data or only search specific date ranges.
Indexes may not contain uppercase characters.
For weekly indexes ISO 8601 format is recommended, eg. logstash-%{+xxxx.ww}

[[plugins-outputs-elasticsearch-index_type]]
===== `index_type` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The index type to write events to. Generally you should try to write only
similar events to the same 'type'. String expansion `%{foo}` works here.

[[plugins-outputs-elasticsearch-manage_template]]
===== `manage_template` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Starting in Logstash 1.3 (unless you set option `manage_template` to false)
a default mapping template for Elasticsearch will be applied, if you do not
already have one set to match the index pattern defined (default of
`logstash-%{+YYYY.MM.dd}`), minus any variables.  For example, in this case
the template will be applied to all indices starting with `logstash-*`

If you have dynamic templating (e.g. creating indices based on field names)
then you should set `manage_template` to false and use the REST API to upload
your templates manually.

[[plugins-outputs-elasticsearch-max_inflight_requests]]
===== `max_inflight_requests`  (DEPRECATED)

  * DEPRECATED WARNING: This configuration item is deprecated and may not be available in future versions.
  * Value type is <<number,number>>
  * Default value is `50`

This setting no longer does anything. It exists to keep config validation
from failing. It will be removed in future versions.

[[plugins-outputs-elasticsearch-node_name]]
===== `node_name` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The node name Elasticsearch will use when joining a cluster.

By default, this is generated internally by the ES client.

[[plugins-outputs-elasticsearch-password]]
===== `password` 

  * Value type is <<password,password>>
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-port]]
===== `port` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The port for Elasticsearch transport to use.

If you do not set this, the following defaults are used:
* `protocol => http` - port 9200
* `protocol => transport` - port 9300-9305
* `protocol => node` - port 9300-9305

[[plugins-outputs-elasticsearch-protocol]]
===== `protocol` 

  * Value can be any of: `node`, `transport`, `http`
  * There is no default value for this setting.

Choose the protocol used to talk to Elasticsearch.

The 'node' protocol will connect to the cluster as a normal Elasticsearch
node (but will not store data). This allows you to use things like
multicast discovery. If you use the `node` protocol, you must permit
bidirectional communication on the port 9300 (or whichever port you have
configured).

The 'transport' protocol will connect to the host you specify and will
not show up as a 'node' in the Elasticsearch cluster. This is useful
in situations where you cannot permit connections outbound from the
Elasticsearch cluster to this Logstash server.

The 'http' protocol will use the Elasticsearch REST/HTTP interface to talk
to elasticsearch.

All protocols will use bulk requests when talking to Elasticsearch.

The default `protocol` setting under java/jruby is "node". The default
`protocol` on non-java rubies is "http"

[[plugins-outputs-elasticsearch-s3_protocol]]
===== `s3_protocol` 

  * Value can be any of: `http`, `https`
  * There is no default value for this setting.



[[plugins-outputs-elasticsearch-ssl]]
===== `ssl` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

SSL Configurations (HTTP only)

Enable SSL

[[plugins-outputs-elasticsearch-tags]]
===== `tags`  (DEPRECATED)

  * DEPRECATED WARNING: This configuration item is deprecated and may not be available in future versions.
  * Value type is <<array,array>>
  * Default value is `[]`

Only handle events with all of these tags.  Note that if you specify
a type, the event must also match that type.
Optional.

[[plugins-outputs-elasticsearch-template]]
===== `template` 

  * Value type is <<path,path>>
  * There is no default value for this setting.

You can set the path to your own template here, if you so desire.
If not set, the included template will be used.

[[plugins-outputs-elasticsearch-template_name]]
===== `template_name` 

  * Value type is <<string,string>>
  * Default value is `"logstash"`

This configuration option defines how the template is named inside Elasticsearch.
Note that if you have used the template management features and subsequently
change this, you will need to prune the old template manually, e.g.

`curl -XDELETE <http://localhost:9200/_template/OldTemplateName?pretty>`

where `OldTemplateName` is whatever the former setting was.

[[plugins-outputs-elasticsearch-template_overwrite]]
===== `template_overwrite` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Overwrite the current template with whatever is configured
in the `template` and `template_name` directives.

[[plugins-outputs-elasticsearch-truststore]]
===== `truststore` 

  * Value type is <<path,path>>
  * There is no default value for this setting.

The JKS truststore to validate the server's certificate
Use either `:truststore` or `:cacert`

[[plugins-outputs-elasticsearch-truststore_password]]
===== `truststore_password` 

  * Value type is <<password,password>>
  * There is no default value for this setting.

Set the truststore password

[[plugins-outputs-elasticsearch-type]]
===== `type`  (DEPRECATED)

  * DEPRECATED WARNING: This configuration item is deprecated and may not be available in future versions.
  * Value type is <<string,string>>
  * Default value is `""`

The type to act on. If a type is given, then this output will only
act on messages with the same type. See any input plugin's `type`
attribute for more.
Optional.

[[plugins-outputs-elasticsearch-user]]
===== `user` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Username and password (HTTP only)

[[plugins-outputs-elasticsearch-workers]]
===== `workers` 

  * Value type is <<number,number>>
  * Default value is `1`

The number of workers to use for this output.
Note that this setting may not be useful for all outputs.

