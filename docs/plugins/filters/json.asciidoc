[[plugins-filters-json]]
=== json

* Version: 3.0.2
* Released on: July 14, 2016
* https://github.com/logstash-plugins/logstash-filter-json/blob/master/CHANGELOG.md#302[Changelog]



==== Getting Help

For questions about the plugin, open a topic in the http://discuss.elastic.co[Discuss] forums. For bugs or feature requests, open an issue in https://github.com/elastic/logstash[Github].
For the list of Elastic supported plugins, please consult the https://www.elastic.co/support/matrix#show_logstash_plugins[Elastic Support Matrix].

==== Description

This is a JSON parsing filter. It takes an existing field which contains JSON and
expands it into an actual data structure within the Logstash event.

By default it will place the parsed JSON in the root (top level) of the Logstash event, but this
filter can be configured to place the JSON into any arbitrary event field, using the
`target` configuration.

This plugin has a few fallback scenario when something bad happen during the parsing of the event.
If the JSON parsing fails on the data, the event will be untouched and it will be tagged with a
`_jsonparsefailure` then you can use conditionals to clean the data. You can configured this tag with then
`tag_on_failure` option.

If the parsed data contains a `@timestamp` field, we will try to use it for the event's `@timestamp`, if the
parsing fails, the field will be renamed to `_@timestamp` and the event will be tagged with a
`_timestampparsefailure`.

&nbsp;

==== Synopsis

This plugin supports the following configuration options:

Required configuration options:

[source,json]
--------------------------
json {
    source => ...
}
--------------------------



Available configuration options:

[cols="<,<,<",options="header",]
|=======================================================================
|Setting |Input type|Required
| <<plugins-filters-json-add_field>> |<<hash,hash>>|No
| <<plugins-filters-json-add_tag>> |<<array,array>>|No
| <<plugins-filters-json-enable_metric>> |<<boolean,boolean>>|No
| <<plugins-filters-json-id>> |<<string,string>>|No
| <<plugins-filters-json-periodic_flush>> |<<boolean,boolean>>|No
| <<plugins-filters-json-remove_field>> |<<array,array>>|No
| <<plugins-filters-json-remove_tag>> |<<array,array>>|No
| <<plugins-filters-json-skip_on_invalid_json>> |<<boolean,boolean>>|No
| <<plugins-filters-json-source>> |<<string,string>>|Yes
| <<plugins-filters-json-tag_on_failure>> |<<array,array>>|No
| <<plugins-filters-json-target>> |<<string,string>>|No
|=======================================================================


==== Details

&nbsp;

[[plugins-filters-json-add_field]]
===== `add_field` 

  * Value type is <<hash,hash>>
  * Default value is `{}`

If this filter is successful, add any arbitrary fields to this event.
Field names can be dynamic and include parts of the event using the `%{field}`.

Example:
[source,ruby]
-----
    filter {
      json {
        add_field => { "foo_%{somefield}" => "Hello world, from %{host}" }
      }
    }
-----

[source,ruby]
-----
    # You can also add multiple fields at once:
    filter {
      json {
        add_field => {
          "foo_%{somefield}" => "Hello world, from %{host}"
          "new_field" => "new_static_value"
        }
      }
    }
-----

If the event has field `"somefield" == "hello"` this filter, on success,
would add field `foo_hello` if it is present, with the
value above and the `%{host}` piece replaced with that value from the
event. The second example would also add a hardcoded field.

[[plugins-filters-json-add_tag]]
===== `add_tag` 

  * Value type is <<array,array>>
  * Default value is `[]`

If this filter is successful, add arbitrary tags to the event.
Tags can be dynamic and include parts of the event using the `%{field}`
syntax.

Example:
[source,ruby]
-----
    filter {
      json {
        add_tag => [ "foo_%{somefield}" ]
      }
    }
-----

[source,ruby]
-----
    # You can also add multiple tags at once:
    filter {
      json {
        add_tag => [ "foo_%{somefield}", "taggedy_tag"]
      }
    }
-----

If the event has field `"somefield" == "hello"` this filter, on success,
would add a tag `foo_hello` (and the second example would of course add a `taggedy_tag` tag).

[[plugins-filters-json-enable_metric]]
===== `enable_metric` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Disable or enable metric logging for this specific plugin instance
by default we record all the metrics we can, but you can disable metrics collection
for a specific plugin.

[[plugins-filters-json-id]]
===== `id` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Add a unique `ID` to the plugin configuration. If no ID is specified, Logstash will generate one. 
It is strongly recommended to set this ID in your configuration. This is particularly useful 
when you have two or more plugins of the same type, for example, if you have 2 grok filters. 
Adding a named ID in this case will help in monitoring Logstash when using the monitoring APIs.

[source,ruby]
-----
output {
 stdout {
   id => "my_plugin_id"
 }
}
-----


[[plugins-filters-json-periodic_flush]]
===== `periodic_flush` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Call the filter flush method at regular interval.
Optional.

[[plugins-filters-json-remove_field]]
===== `remove_field` 

  * Value type is <<array,array>>
  * Default value is `[]`

If this filter is successful, remove arbitrary fields from this event.
Fields names can be dynamic and include parts of the event using the %{field}

Example:
[source,ruby]
-----
    filter {
      json {
        remove_field => [ "foo_%{somefield}" ]
      }
    }
-----

[source,ruby]
-----
    # You can also remove multiple fields at once:
    filter {
      json {
        remove_field => [ "foo_%{somefield}", "my_extraneous_field" ]
      }
    }
-----

If the event has field `"somefield" == "hello"` this filter, on success,
would remove the field with name `foo_hello` if it is present. The second
example would remove an additional, non-dynamic field.

[[plugins-filters-json-remove_tag]]
===== `remove_tag` 

  * Value type is <<array,array>>
  * Default value is `[]`

If this filter is successful, remove arbitrary tags from the event.
Tags can be dynamic and include parts of the event using the `%{field}`
syntax.

Example:
[source,ruby]
-----
    filter {
      json {
        remove_tag => [ "foo_%{somefield}" ]
      }
    }
-----

[source,ruby]
-----
    # You can also remove multiple tags at once:
    filter {
      json {
        remove_tag => [ "foo_%{somefield}", "sad_unwanted_tag"]
      }
    }
-----

If the event has field `"somefield" == "hello"` this filter, on success,
would remove the tag `foo_hello` if it is present. The second example
would remove a sad, unwanted tag as well.

[[plugins-filters-json-skip_on_invalid_json]]
===== `skip_on_invalid_json` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Allow to skip filter on invalid json (allows to handle json and non-json data without warnings)

[[plugins-filters-json-source]]
===== `source` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.

The configuration for the JSON filter:

[source,ruby]
-----
    source => source_field
-----

For example, if you have JSON data in the `message` field:

[source,ruby]
-----
    filter {
      json {
        source => "message"
      }
    }
-----

The above would parse the json from the `message` field

[[plugins-filters-json-tag_on_failure]]
===== `tag_on_failure` 

  * Value type is <<array,array>>
  * Default value is `["_jsonparsefailure"]`

Append values to the `tags` field when there has been no
successful match

[[plugins-filters-json-target]]
===== `target` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Define the target field for placing the parsed data. If this setting is
omitted, the JSON data will be stored at the root (top level) of the event.

For example, if you want the data to be put in the `doc` field:

[source,ruby]
-----
    filter {
      json {
        target => "doc"
      }
    }
-----

JSON in the value of the `source` field will be expanded into a
data structure in the `target` field.

NOTE: if the `target` field already exists, it will be overwritten!


